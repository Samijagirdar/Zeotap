{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c072d90a-7207-4f89-8cbc-54ef7933983a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "498dba1b-b537-4d40-bbe4-a605173bf45b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "customers = pd.read_csv('Customers.csv')\n",
    "products = pd.read_csv('Products.csv')\n",
    "transactions = pd.read_csv('Transactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ed97ad23-0d3e-4f74-9b21-93d2ddbefb80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged Data is   TransactionID CustomerID ProductID      TransactionDate  Quantity  \\\n",
      "0        T00001      C0199      P067  2024-08-25 12:38:23         1   \n",
      "1        T00761      C0199      P022  2024-10-01 05:57:09         4   \n",
      "2        T00626      C0199      P079  2024-08-17 12:06:08         2   \n",
      "3        T00963      C0199      P008  2024-10-26 00:01:58         2   \n",
      "4        T00112      C0146      P067  2024-05-27 22:23:54         1   \n",
      "\n",
      "   TotalValue  Price_x                      ProductName     Category  Price_y  \\\n",
      "0      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
      "1      550.16   137.54               HomeSense Wall Art   Home Decor   137.54   \n",
      "2      834.74   417.37                   ActiveWear Rug   Home Decor   417.37   \n",
      "3      293.70   146.85      BookWorld Bluetooth Speaker  Electronics   146.85   \n",
      "4      300.68   300.68  ComfortLiving Bluetooth Speaker  Electronics   300.68   \n",
      "\n",
      "      CustomerName  Region  SignupDate  \n",
      "0   Andrea Jenkins  Europe  2022-12-03  \n",
      "1   Andrea Jenkins  Europe  2022-12-03  \n",
      "2   Andrea Jenkins  Europe  2022-12-03  \n",
      "3   Andrea Jenkins  Europe  2022-12-03  \n",
      "4  Brittany Harvey    Asia  2024-09-04  \n"
     ]
    }
   ],
   "source": [
    "# Step 1: Data Preprocessing\n",
    "# Merge datasets\n",
    "transactions_products = pd.merge(transactions, products, on=\"ProductID\", how=\"inner\")\n",
    "merged_data = pd.merge(transactions_products, customers, on=\"CustomerID\", how=\"inner\")\n",
    "\n",
    "print(\"Merged Data is\",merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6487a2c8-b942-41b6-86be-63c6666bc185",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Feature Engineering\n",
    "# Aggregate transaction data by CustomerID\n",
    "# Use the appropriate 'Price' column\n",
    "if 'Price_y' in merged_data.columns:\n",
    "    price_column = 'Price_y'  # Assuming 'Price_y' is from products dataset\n",
    "elif 'Price_x' in merged_data.columns:\n",
    "    price_column = 'Price_x'  # Fallback in case the correct one is 'Price_x'\n",
    "else:\n",
    "    raise KeyError(\"No valid 'Price' column found in merged_data.\")\n",
    "\n",
    "# Aggregate transaction data by CustomerID\n",
    "customer_features = merged_data.groupby(\"CustomerID\").agg({\n",
    "    \"Quantity\": \"sum\",         # Total products purchased\n",
    "    price_column: \"mean\",      # Average price of purchased products\n",
    "    \"TotalValue\": \"sum\",       # Total transaction value\n",
    "    \"Region\": \"first\",         # Keep the region as a feature\n",
    "}).reset_index()\n",
    "\n",
    "# Rename the price column for clarity\n",
    "customer_features.rename(columns={price_column: \"AveragePrice\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "25babc7b-8be7-4628-b5cc-622d68584955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical features (e.g., Region)\n",
    "customer_features = pd.get_dummies(customer_features, columns=[\"Region\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "18444b77-013a-4512-856e-37f48f922eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "numerical_cols = [\"Quantity\", \"AveragePrice\", \"TotalValue\"]  # Use the renamed 'Price' column\n",
    "customer_features[numerical_cols] = scaler.fit_transform(customer_features[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e7dd0def-4545-402a-800d-28a9ea7e6383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Compute Similarity\n",
    "# Compute the similarity matrix using cosine similarity\n",
    "feature_matrix = customer_features.drop(columns=[\"CustomerID\"]).values\n",
    "similarity_matrix = cosine_similarity(feature_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "3acc16e7-b4cb-41bc-8925-316b12389cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Find Top 3 Lookalikes for Each Customer\n",
    "lookalike_map = {}\n",
    "for idx, customer_id in enumerate(customer_features[\"CustomerID\"]):\n",
    "    # Get similarity scores for the current customer\n",
    "    similarity_scores = similarity_matrix[idx]\n",
    "    \n",
    "    # Exclude the current customer (self-similarity)\n",
    "    similar_customers = [\n",
    "        (customer_features[\"CustomerID\"].iloc[i], similarity_scores[i]) \n",
    "        for i in range(len(similarity_scores)) if i != idx\n",
    "    ]\n",
    "    \n",
    "    # Sort by similarity score in descending order and take top 3\n",
    "    top_3_similar = sorted(similar_customers, key=lambda x: x[1], reverse=True)[:3]\n",
    "    \n",
    "    # Add to the lookalike map\n",
    "    lookalike_map[customer_id] = top_3_similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "865a4c80-b52b-42da-aa21-d09fc27f5603",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lookalike.csv has been created with top 3 lookalikes for the first 20 customers.\n"
     ]
    }
   ],
   "source": [
    "# Step 5: Generate Lookalike.csv for the First 20 Customers\n",
    "lookalike_subset = {cust_id: lookalike_map[cust_id] for cust_id in customer_features[\"CustomerID\"][:20]}\n",
    "\n",
    "# Convert to desired format and save as CSV\n",
    "lookalike_df = pd.DataFrame([\n",
    "    {\"cust_id\": cust_id, \"lookalikes\": json.dumps(lookalike_subset[cust_id])}\n",
    "    for cust_id in lookalike_subset\n",
    "])\n",
    "lookalike_df.to_csv(\"Lookalike.csv\", index=False)\n",
    "\n",
    "print(\"Lookalike.csv has been created with top 3 lookalikes for the first 20 customers.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
